{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to set up an S3 client object and define the locations within your default S3 bucket for storing the model artifacts. This step involves the automatic creation of a write bucket named sagemaker-<your-Region>-<your-account-id>, facilitated by the SageMaker session object as shown through sess.default_bucket(). Additionally, for training purposes, the datasets are located in a publicly accessible S3 bucket named sagemaker-sample-files. This bucket is referred to as the read bucket, and its specific location is determined by the read prefix, as indicated on line 29 of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Importing the pandas library for data manipulation and analysis.\n",
    "import numpy as np  # Importing the numpy library for numerical operations.\n",
    "import boto3  # Importing the boto3 library to interact with AWS services.\n",
    "import sagemaker  # Importing the sagemaker library for building, training, and deploying machine learning models on AWS SageMaker.\n",
    "import time  # Importing the time library for time-related tasks.\n",
    "import json  # Importing the json library for JSON parsing.\n",
    "import io  # Importing the io library for handling I/O stream operations.\n",
    "from io import StringIO  # Importing StringIO from io for in-memory text streams.\n",
    "import base64  # Importing the base64 library for encoding and decoding Base64 data.\n",
    "import pprint  # Importing the pprint library for pretty-printing Python data structures.\n",
    "import re  # Importing the re library for regular expression operations.\n",
    "\n",
    "from sagemaker.image_uris import retrieve  # Importing the retrieve function from sagemaker.image_uris for retrieving container image URIs.\n",
    "\n",
    "sess = sagemaker.Session()  # Creating a SageMaker session object for managing interactions with the SageMaker service.\n",
    "write_bucket = sess.default_bucket()  # Retrieving the default S3 bucket for the SageMaker session.\n",
    "write_prefix = \"fraud-detect-demo\"  # Defining the S3 prefix for writing data related to the fraud detection demo.\n",
    "\n",
    "region = sess.boto_region_name  # Retrieving the AWS region name associated with the SageMaker session.\n",
    "s3_client = boto3.client(\"s3\", region_name=region)  # Creating an S3 client for interacting with Amazon S3.\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=region)  # Creating a SageMaker client for interacting with the SageMaker service.\n",
    "sm_runtime_client = boto3.client(\"sagemaker-runtime\")  # Creating a SageMaker Runtime client for invoking deployed models.\n",
    "sm_autoscaling_client = boto3.client(\"application-autoscaling\")  # Creating an Application Auto Scaling client for managing auto-scaling policies.\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()  # Retrieving the IAM role for SageMaker execution.\n",
    "\n",
    "# S3 locations used for parameterizing the notebook run\n",
    "read_bucket = \"sagemaker-sample-files\"  # Defining the S3 bucket for reading sample files.\n",
    "read_prefix = \"datasets/tabular/synthetic_automobile_claims\"  # Defining the S3 prefix for reading synthetic automobile claims data.\n",
    "model_prefix = \"models/xgb-fraud\"  # Defining the S3 prefix for the XGBoost fraud detection model.\n",
    "\n",
    "data_capture_key = f\"{write_prefix}/data-capture\"  # Defining the S3 key for data capture during model inference.\n",
    "\n",
    "# S3 location of trained model artifact\n",
    "model_uri = f\"s3://{read_bucket}/{model_prefix}/fraud-det-xgb-model.tar.gz\"  # Defining the S3 URI of the trained XGBoost model artifact.\n",
    "\n",
    "# S3 path where data captured at endpoint will be stored\n",
    "data_capture_uri = f\"s3://{write_bucket}/{data_capture_key}\"  # Defining the S3 URI for storing data captured at the inference endpoint.\n",
    "\n",
    "# S3 location of test data\n",
    "test_data_uri = f\"s3://{read_bucket}/{read_prefix}/test.csv\"  # Defining the S3 URI for the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a SageMaker model from the model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the SageMaker managed XGBoost image\n",
    "training_image = retrieve(framework=\"xgboost\", region=region, version=\"1.3-1\")\n",
    "\n",
    "# Specify a unique model name that does not exist\n",
    "model_name = \"fraud-detect-xgb\"\n",
    "primary_container = {\n",
    "                     \"Image\": training_image,\n",
    "                     \"ModelDataUrl\": model_uri\n",
    "                    }\n",
    "\n",
    "model_matches = sm_client.list_models(NameContains=model_name)[\"Models\"]\n",
    "if not model_matches:\n",
    "    model = sm_client.create_model(ModelName=model_name,\n",
    "                                   PrimaryContainer=primary_container,\n",
    "                                   ExecutionRoleArn=sagemaker_role)\n",
    "else:\n",
    "    print(f\"Model with name {model_name} already exists! Change model name to create new\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create an endpoint configuration to specify properties, including instance type and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f\"{model_name}-endpoint\"\n",
    "\n",
    "endpoint_matches = sm_client.list_endpoints(NameContains=endpoint_name)[\"Endpoints\"]\n",
    "if not endpoint_matches:\n",
    "    endpoint_response = sm_client.create_endpoint(\n",
    "                                                  EndpointName=endpoint_name,\n",
    "                                                  EndpointConfigName=endpoint_config_name\n",
    "                                                 )\n",
    "else:\n",
    "    print(f\"Endpoint with name {endpoint_name} already exists! Change endpoint name to create new\")\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "while status == \"Creating\":\n",
    "    print(f\"Endpoint Status: {status}...\")\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "print(f\"Endpoint Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create the endpoint using the endpoint configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f\"{model_name}-endpoint\"\n",
    "\n",
    "endpoint_matches = sm_client.list_endpoints(NameContains=endpoint_name)[\"Endpoints\"]\n",
    "if not endpoint_matches:\n",
    "    endpoint_response = sm_client.create_endpoint(\n",
    "                                                  EndpointName=endpoint_name,\n",
    "                                                  EndpointConfigName=endpoint_config_name\n",
    "                                                 )\n",
    "else:\n",
    "    print(f\"Endpoint with name {endpoint_name} already exists! Change endpoint name to create new\")\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "while status == \"Creating\":\n",
    "    print(f\"Endpoint Status: {status}...\")\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "print(f\"Endpoint Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Invoke the inference endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch test data to run predictions with the endpoint\n",
    "test_df = pd.read_csv(test_data_uri)\n",
    "\n",
    "# For content type text/csv, payload should be a string with commas separating the values for each feature\n",
    "# This is the inference request serialization step\n",
    "# CSV serialization\n",
    "csv_file = io.StringIO()\n",
    "test_sample = test_df.drop([\"fraud\"], axis=1).iloc[:5]\n",
    "test_sample.to_csv(csv_file, sep=\",\", header=False, index=False)\n",
    "payload = csv_file.getvalue()\n",
    "response = sm_runtime_client.invoke_endpoint(\n",
    "                                             EndpointName=endpoint_name,\n",
    "                                             Body=payload,\n",
    "                                             ContentType=\"text/csv\",\n",
    "                                             Accept=\"text/csv\"\n",
    "                                            )\n",
    "\n",
    "# This is the inference response deserialization step\n",
    "# This is a bytes object\n",
    "result = response[\"Body\"].read()\n",
    "# Decoding bytes to a string\n",
    "result = result.decode(\"utf-8\")\n",
    "# Converting to list of predictions\n",
    "result = re.split(\",|\\n\",result)\n",
    "\n",
    "prediction_df = pd.DataFrame()\n",
    "prediction_df[\"Prediction\"] = result[:5]\n",
    "prediction_df[\"Label\"] = test_df[\"fraud\"].iloc[:5].values\n",
    "prediction_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because data capture was set up in the endpoint configuration, you have a way to inspect what payload was sent to the endpoint alongside its response. The captured data takes some time to get fully uploaded to S3. Check if data capture is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "print(\"Waiting for captures to show up\", end=\"\")\n",
    "for _ in range(90):\n",
    "    capture_files = sorted(S3Downloader.list(f\"{data_capture_uri}/{endpoint_name}\"))\n",
    "    if capture_files:\n",
    "        capture_file = S3Downloader.read_file(capture_files[-1]).split(\"\\n\")\n",
    "        capture_record = json.loads(capture_file[0])\n",
    "        if \"inferenceId\" in capture_record[\"eventMetadata\"]:\n",
    "            break\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    time.sleep(1)\n",
    "print()\n",
    "print(f\"Found {len(capture_files)} Data Capture Files:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The captured data is stored as a separate file for each endpoint invocation in S3 in JSON Lines, a newline-delimited format to store structured data where each line is a JSON value. Copy and paste the following code to retrieve the data capture files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_files = sorted(S3Downloader.list(f\"{data_capture_uri}/{endpoint_name}\"))\n",
    "capture_file = S3Downloader.read_file(capture_files[0]).split(\"\\n\")\n",
    "capture_record = json.loads(capture_file[0])\n",
    "capture_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The following code to decode the data in the captured files using base64. The code retrieves the five test samples that were sent in as payload, and their predictions. This feature is useful in inspecting endpoint loads with model responses and monitor the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = capture_record[\"captureData\"][\"endpointInput\"][\"data\"]\n",
    "output_data = capture_record[\"captureData\"][\"endpointOutput\"][\"data\"]\n",
    "input_data_list = base64.b64decode(input_data).decode(\"utf-8\").split(\"\\n\")\n",
    "print(input_data_list)\n",
    "output_data_list = base64.b64decode(output_data).decode(\"utf-8\").split(\"\\n\")\n",
    "print(output_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure auto scaling for endpoint\n",
    "Auto scaling can be set up in two steps. First, you configure a scaling policy with details of minimum, desired, and maximum number of instances per endpoint. Copy and paste the following code to configure a target tracking scaling policy. The specified maximum number of instances are launched when traffic goes over chosen thresholds, which you choose in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "# SageMaker expects resource id to be provided with the following structure\n",
    "resource_id = f\"endpoint/{endpoint_name}/variant/{resp['ProductionVariants'][0]['VariantName']}\"\n",
    "\n",
    "# Scaling configuration\n",
    "scaling_config_response = sm_autoscaling_client.register_scalable_target(\n",
    "                                                          ServiceNamespace=\"sagemaker\",\n",
    "                                                          ResourceId=resource_id,\n",
    "                                                          ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\", \n",
    "                                                          MinCapacity=1,\n",
    "                                                          MaxCapacity=2\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the scaling policy. The chosen scaling metric is SageMakerVariantInvocationsPerInstance, which is the average number of times per minute that each inference instance for a model variant is invoked. When this number crosses the chosen threshold of 5, the auto scaling is triggered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Scaling Policy\n",
    "policy_name = f\"scaling-policy-{endpoint_name}\"\n",
    "scaling_policy_response = sm_autoscaling_client.put_scaling_policy(\n",
    "                                                PolicyName=policy_name,\n",
    "                                                ServiceNamespace=\"sagemaker\",\n",
    "                                                ResourceId=resource_id,\n",
    "                                                ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "                                                PolicyType=\"TargetTrackingScaling\",\n",
    "                                                TargetTrackingScalingPolicyConfiguration={\n",
    "                                                    \"TargetValue\": 5.0, # Target for avg invocations per minutes\n",
    "                                                    \"PredefinedMetricSpecification\": {\n",
    "                                                        \"PredefinedMetricType\": \"SageMakerVariantInvocationsPerInstance\",\n",
    "                                                    },\n",
    "                                                    \"ScaleInCooldown\": 600, # Duration in seconds until scale in\n",
    "                                                    \"ScaleOutCooldown\": 60 # Duration in seconds between scale out\n",
    "                                                }\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retrieve the scaling policy details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_autoscaling_client.describe_scaling_policies(ServiceNamespace=\"sagemaker\")\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4, depth=4)\n",
    "for i in response[\"ScalingPolicies\"]:\n",
    "    pp.pprint(i[\"PolicyName\"])\n",
    "    print(\"\")\n",
    "    if(\"TargetTrackingScalingPolicyConfiguration\" in i):\n",
    "        pp.pprint(i[\"TargetTrackingScalingPolicyConfiguration\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stress-test the endpoint. The code runs for 250 seconds and invokes the endpoint repeatedly by sending randomly selected samples from the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_duration = 250\n",
    "end_time = time.time() + request_duration\n",
    "print(f\"Endpoint will be tested for {request_duration} seconds\")\n",
    "while time.time() < end_time:\n",
    "    csv_file = io.StringIO()\n",
    "    test_sample = test_df.drop([\"fraud\"], axis=1).iloc[[np.random.randint(0, test_df.shape[0])]]\n",
    "    test_sample.to_csv(csv_file, sep=\",\", header=False, index=False)\n",
    "    payload = csv_file.getvalue()\n",
    "    response = sm_runtime_client.invoke_endpoint(\n",
    "                                                 EndpointName=endpoint_name,\n",
    "                                                 Body=payload,\n",
    "                                                 ContentType=\"text/csv\"\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the endpoint receives the increased payload, you can check the status of the endpoint by running the code below. This code checks when the status of the endpoint changes from InService to Updating and keeps track of the instance counts. After a few minutes, you can see the status changing from InService to Updating and back to InService but with a higher instance count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the instance counts after the endpoint gets more load\n",
    "response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "endpoint_status = response[\"EndpointStatus\"]\n",
    "request_duration = 250\n",
    "end_time = time.time() + request_duration\n",
    "print(f\"Waiting for Instance count increase for a max of {request_duration} seconds. Please re run this cell in case the count does not change\")\n",
    "while time.time() < end_time:\n",
    "    response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    endpoint_status = response[\"EndpointStatus\"]\n",
    "    instance_count = response[\"ProductionVariants\"][0][\"CurrentInstanceCount\"]\n",
    "    print(f\"Status: {endpoint_status}\")\n",
    "    print(f\"Current Instance count: {instance_count}\")\n",
    "    if (endpoint_status==\"InService\") and (instance_count>1):\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
